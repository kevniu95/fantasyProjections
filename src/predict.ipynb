{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/created/reg_set.p', 'rb') as handle:\n",
    "    reg_set1 = pickle.load(handle)\n",
    "\n",
    "final_reg = reg_set1[reg_set1['Year'] != 2022]\n",
    "final_pred = reg_set1[reg_set1['Year'] == 2022]\n",
    "\n",
    "exclude1415 = True\n",
    "if exclude1415:\n",
    "    final_reg = final_reg[final_reg['Year'] > 2015].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg_train, reg_test = train_test_split(final_reg, test_size = 0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    \n",
    "base_vars = ['AverageDraftPositionPPR',\n",
    "            'AverageDraftPositionPPRSq',\n",
    "            'foundAdp',\n",
    "            'QB','RB','TE','WR']\n",
    "base_x = (reg_train[base_vars].copy(), reg_test[base_vars].copy())\n",
    "\n",
    "x_vars = ['Year',\n",
    "            'AverageDraftPositionPPR',\n",
    "            'AverageDraftPositionPPRSq',\n",
    "            'foundAdp',\n",
    "            'PrvPts_PPR',\n",
    "            'foundLastYearStats',\n",
    "            'qbDiff',\n",
    "            'Draft',\n",
    "            'Age',\n",
    "            'PrvYrTmPts',\n",
    "            'PlayersAtPosition',\n",
    "            'PrvYrPtsShare',\n",
    "            'QB','RB','TE','WR']\n",
    "x = (reg_train[x_vars].copy(), reg_test[x_vars].copy())\n",
    "\n",
    "\n",
    "y_pts = (reg_train['Pts_PPR'].copy(), reg_test['Pts_PPR'].copy())\n",
    "y_cl = (reg_train['aboveBase'].copy(), reg_test['aboveBase'].copy())\n",
    "\n",
    "# def encodeYears(x):\n",
    "#     encoder = OneHotEncoder()\n",
    "#     y = x.copy()\n",
    "#     yrNames = [str(i) for i in list(y['Year'].unique())]\n",
    "#     yrNames.sort()\n",
    "#     y[yrNames] = encoder.fit_transform(y[['Year']]).toarray()\n",
    "#     return y.drop('Year', axis = 1)\n",
    "\n",
    "\n",
    "x_0 = tuple([i.drop('Year', axis = 1) for i in list(x)])\n",
    "# x_a = tuple([encodeYears(i) for i in list(x)])\n",
    "\n",
    "# x_b1, y_pts_b1, y_cl_b1 = \n",
    "# x_b2 = encodeYears(x_b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predict points scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score on training data 0.6802859088101214\n",
      "R^2 score on test data 0.674309232119654\n",
      "\n",
      "R^2 score on training data 0.5783228258371138\n",
      "R^2 score on test data 0.5801931855422693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "def try_lassos(X, y, polys = 2):\n",
    "    X_train, X_test  = X\n",
    "    y_train, y_test = y\n",
    "    X_train = X_train.reset_index().drop('index', axis = 1)\n",
    "    y_train = np.array(y_train, dtype = float)\n",
    "    model = make_pipeline(PolynomialFeatures(polys), MaxAbsScaler(), LassoCV(cv = 5, random_state = 0, max_iter = 500000))\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"R^2 score on training data {model.score(X_train, y_train)}\")\n",
    "    print(f\"R^2 score on test data {model.score(X_test, y_test)}\")\n",
    "    print()\n",
    "    return model\n",
    "\n",
    "full_pts_model =try_lassos(x_0, y_pts, polys = 2)\n",
    "# try_lassos(x_a, y_pts, polys = 2)\n",
    "adp_pts_model = try_lassos(base_x, y_pts, polys = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predict starter percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def try_classifier(classifier, X, y, polys = 2):\n",
    "    X_train, X_test  = X\n",
    "    y_train, y_test = y\n",
    "    X_train = X_train.reset_index().drop('index', axis = 1)\n",
    "    y_train = np.array(y_train, dtype = float)\n",
    "    model = make_pipeline(PolynomialFeatures(polys), MaxAbsScaler(), classifier)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv = 5)\n",
    "    # print(scores)\n",
    "    return scores.sum() / len(scores)\n",
    "\n",
    "def run_model(classifier, X, y, polys = 2):\n",
    "    X_train, X_test  = X\n",
    "    y_train, y_test = y\n",
    "    X_train = X_train.reset_index().drop('index', axis = 1)\n",
    "    y_train = np.array(y_train, dtype = float)\n",
    "    model = make_pipeline(PolynomialFeatures(polys), MaxAbsScaler(), classifier)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Score on training data {model.score(X_train, y_train)}\")\n",
    "    print(f\"Score on test data {model.score(X_test, y_test)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "0.9309139784946237\n",
      "\n",
      "Score on training data 0.9354838709677419\n",
      "Score on test data 0.9398496240601504\n",
      "0.25\n",
      "0.9309139784946237\n",
      "\n",
      "Score on training data 0.9314516129032258\n",
      "Score on test data 0.9377013963480129\n"
     ]
    }
   ],
   "source": [
    "def testLogReg(x, y):\n",
    "    best_c = None\n",
    "    c_max = 0\n",
    "    for c in [0.01, 0.1, 0.25, 0.33, 0.5, 0.95, 0.995, 1, 1.005, 1.05, 1.5]:\n",
    "        a = LogisticRegression(penalty = 'l2', C = c, max_iter = 1000)\n",
    "        res = try_classifier(a, x, y)\n",
    "        if res >= c_max:\n",
    "            best_c = c\n",
    "            c_max = res\n",
    "    print(best_c)\n",
    "    print(c_max)\n",
    "    print()\n",
    "\n",
    "    final_model = LogisticRegression(penalty = 'l2', C = best_c, max_iter = 1000)\n",
    "    final_model = run_model(final_model, x, y)\n",
    "    return final_model\n",
    "\n",
    "final_lr_model = testLogReg(x_0, y_cl)\n",
    "base_lr_model = testLogReg(base_x, y_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "0.932258064516129\n",
      "\n",
      "Score on training data 0.9362903225806452\n",
      "Score on test data 0.9215896885069818\n",
      "1.05\n",
      "0.9336021505376344\n",
      "\n",
      "Score on training data 0.935752688172043\n",
      "Score on test data 0.9119226638023631\n"
     ]
    }
   ],
   "source": [
    "def testSVM(x, y):\n",
    "    c_max = 0\n",
    "    for c in [0.01, 0.1, 0.25, 0.33, 0.5, 0.95, 0.995, 1, 1.005, 1.05, 1.5]:\n",
    "        a = SVC(C = c)\n",
    "        res = try_classifier(a, x, y)\n",
    "        if res >= c_max:\n",
    "            best_c = c\n",
    "            c_max = res\n",
    "    print(best_c)\n",
    "    print(c_max)\n",
    "    print()\n",
    "            \n",
    "    final_model = SVC(C = best_c)\n",
    "    final_model = run_model(final_model, x, y)\n",
    "    return final_model\n",
    "final_svm_model = testSVM(x_0, y_cl)\n",
    "base_svm_model = testSVM(base_x, y_cl)\n",
    "\n",
    "# base_x[0].columns\n",
    "# base_x[1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. Try Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 500\n",
      "0.9341397849462366\n",
      "\n",
      "Score on training data 0.9475806451612904\n",
      "Score on test data 0.9194414607948442\n",
      "5 500\n",
      "0.9346774193548386\n",
      "\n",
      "Score on training data 0.943010752688172\n",
      "Score on test data 0.9140708915145005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def testRFC(x, y):\n",
    "    c_max = 0\n",
    "    for c in [2, 5]:\n",
    "        for d in [100, 250, 500]:\n",
    "            a = RandomForestClassifier(max_depth = c, n_estimators = d)\n",
    "            res = try_classifier(a, x, y)\n",
    "            if res >= c_max:\n",
    "                best_c = c\n",
    "                best_d = d\n",
    "                c_max = res\n",
    "\n",
    "    print(best_c, best_d)\n",
    "    print(c_max)\n",
    "    print()\n",
    "            \n",
    "    final_model = RandomForestClassifier(max_depth = best_c, n_estimators = d)\n",
    "    final_model = run_model(final_model, x, y)\n",
    "    return final_model\n",
    "\n",
    "final_rfc_model = testRFC(x_0, y_cl)\n",
    "base_rfc_model = testRFC(base_x, y_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. ADP-based projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vars = ['AverageDraftPositionPPR',\n",
    "            'AverageDraftPositionPPRSq',\n",
    "            'foundAdp',\n",
    "            'QB','RB','TE','WR']\n",
    "\n",
    "def prepare_draft_template():\n",
    "    # pred_x = pred_set[['AverageDraftPositionPPR', 'AverageDraftPositionPPRSq', 'foundAdp', 'QB','RB','TE','WR']]\n",
    "    a = np.column_stack((np.arange(1, 201), np.square(np.arange(1, 201)), np.ones(200), \n",
    "                            np.ones(200), np.zeros(200), np.zeros(200), np.zeros(200)))\n",
    "    arrs = [a]\n",
    "    for i in range(4, 7):\n",
    "        tmp = arrs[-1].copy()\n",
    "        tmp[:, [i-1, i]] = tmp[:, [i, i - 1]]\n",
    "        arrs.append(tmp)\n",
    "    return arrs\n",
    "\n",
    "arrs = prepare_draft_template()\n",
    "final = pd.DataFrame(np.concatenate(arrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns = ['AverageDraftPositionPPR', 'AverageDraftPositionPPRSq', 'foundAdp', 'QB','RB','TE','WR']\n",
    "\n",
    "np_res = np.column_stack((adp_pts_model.predict(final), [i[1] for i in base_lr_model.predict_proba(final)]))\n",
    "final_additions = pd.DataFrame(np_res)\n",
    "final_additions.columns = ['Predicted Points', 'Predicted Prob']\n",
    "final = final.join(final_additions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excelBook = load_workbook(EXPORT_FILE)\n",
    "# with pd.ExcelWriter(EXPORT_FILE, engine='xlsxwriter') as writer:\n",
    "#     print(writer)\n",
    "#     # Save your file workbook as base\n",
    "#     writer.sheets = dict((ws.title, ws) for ws in excelBook.worksheets)\n",
    "\n",
    "#     # Now here add your new sheets\n",
    "#     final.to_excel(writer,'saw', index = False)\n",
    "\n",
    "#     # Save the file\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. 2022 Player Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_0 = final_pred[x_vars].copy().drop('Year', axis = 1)\n",
    "x_pred_adp = final_pred[['AverageDraftPositionPPR', 'AverageDraftPositionPPRSq', 'foundAdp', 'QB','RB','TE','WR']]\n",
    "final_pred = final_pred.reset_index().drop('index', axis = 1)\n",
    "final_pred['Preds'] = full_pts_model.predict(x_pred_0)\n",
    "final_pred['Preds_adp'] = adp_pts_model.predict(x_pred_adp)\n",
    "final_pred['Prob'] = [i[1] for i in final_lr_model.predict_proba(x_pred_0)]\n",
    "final_pred.sort_values('AverageDraftPositionPPR', ascending = True, inplace = True)\n",
    "final_pred.columns\n",
    "preds = final_pred[['Player','Tm','FantPos','PrvPts_PPR','AverageDraftPositionPPR','OldQBs',\n",
    "                    'NewQBs','DOB','Draft','Age','PrvYrTmPts','PlayersAtPosition',\n",
    "                    'PrvYrPtsShare','Preds','Preds_adp','Prob']].copy()\n",
    "\n",
    "with open('../projections/player_proj_2022.p', 'wb') as handle:\n",
    "    pickle.dump(preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_FILE = './projections2022.xlsx'\n",
    "with pd.ExcelWriter(EXPORT_FILE, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "    final.to_excel(writer, sheet_name = 'ADPBase', index = False)\n",
    "    preds.to_excel(writer, sheet_name = 'Players2022', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_new2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e08048f17ff008031266911b66a2ac7278627f8d3490a4b4484f3664274d5bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
